<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>线性回归</title>
      <link href="/2023/05/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
      <url>/2023/05/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h2 id="本章内容">本章内容：</h2><p><ahref="#一、线性回归1（最小二乘法及其几何意义）"><strong>1、最小二乘法（矩阵表达与几何意义）</strong></a></p><p><ahref="#二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）"><strong>2、概率角度：最小二乘法noise为Gaussian 的 MLE（最大似然估计）</strong></a></p><p><a href="#三、线性回归3（正则化-岭回归）">**3、正则化</a></p><p><strong><ahref="#四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）">4、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）</a></strong></p><p><strong><a href="#小结">5、小结</a></strong></p><p><strong>符号说明：</strong></p><p>$D={ (x_1,y_1),(x_2,y_2),,(x_N,y_N)} $(数据集)</p><p><span class="math inline">\(x_i\in \mathbb R^p y_i \in \mathbb Ri=1,2,\cdots ,N\)</span></p><p><span class="math inline">\(X=\begin{pmatrix} x_1&amp;x_2&amp;\cdots&amp; x_N \end{pmatrix}^T= \begin{pmatrix}x_1^T\\x_2^T\\\vdots\\x_N^T \end{pmatrix}= \begin{pmatrix}x_{11}&amp;x_{12} &amp; \cdots&amp; x_{1p}\\x_{21}&amp;x_{22}&amp;\cdots&amp;x_{2p}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\ x_{N1}&amp;x_{N2}&amp;\cdots&amp;x_{NP} \end{pmatrix}_{N\times P}\)</span></p><p><span class="math inline">\(Y=\begin{pmatrix} y_1\\y_2\\\vdots\\y_N\end{pmatrix}_{N\times 1}\)</span></p><h3id="一线性回归1最小二乘法及其几何意义">一、线性回归1（最小二乘法及其几何意义）</h3><h4id="矩阵表达下的最小二乘法"><strong>1、矩阵表达下的最小二乘法</strong></h4><p><span class="math inline">\(**Loss Function:**\)</span></p><p><span class="math inline">\(L(W)=\displaystyle\sum^{N}_{i=1}{\VertW^Tx_i-y_i\Vert}^2\)</span></p><blockquote><p>此式为均方差，若 <span class="math inline">\(L\)</span>越小，则回归结果与真实结果越接近 此处 <spanclass="math inline">\(W\)</span> 是一个 <spanclass="math inline">\(p\times 1\)</span> 的向量，表示 <spanclass="math inline">\(x_i\)</span> 的系数 一般情况应该是 <spanclass="math inline">\(W^Tx_i+b\)</span> 此处在 <spanclass="math inline">\(x_i\)</span> 中增加一个 <spanclass="math inline">\(x_{i0}=1\)</span> ，在 <spanclass="math inline">\(W\)</span> 中增加一个 <spanclass="math inline">\(w_0=b\)</span> ，即可用 <spanclass="math inline">\(W^Tx_i\)</span> 表示</p></blockquote><p>$ <span class="math display">\[\begin{equation}\begin{split}L(W)&amp;=\displaystyle\sum^{N}_{i=1}(W^Tx_i-y_i)^2\\ &amp;=\begin{pmatrix} W^Tx_1-y_1 &amp; W^Tx_2-y_2&amp;\cdots&amp;W^Tx_N-y_N\end{pmatrix} \begin{pmatrix}(W^Tx_1-y_1)^T\\(W^Tx_2-y_2)^T\\\vdots\\(W^Tx_N-y_N)^T \end{pmatrix}\\&amp;=[W^T\begin{pmatrix} x_1&amp;x_2&amp;\cdots&amp;x_N \end{pmatrix}-\begin{pmatrix} y_1&amp;y_2&amp;\cdots&amp;y_N \end{pmatrix}]\begin{pmatrix} x_1^TW-y_1^T\\x_2^TW-y_2^T\\\vdots\\x_N^TW-y_N^T\end{pmatrix}\\ &amp;=(W^TX^T - Y^T)(XW-Y)\\&amp;=W^TX^TXW-W^TX^TY-Y^TXW+Y^TY\\ &amp;=W^TX^TXW-2W^TX^TY+Y^TY\end{split}\end{equation}\]</span> $</p><blockquote><p><span class="math inline">\(W^TX^TY=(Y^TXW)^T\)</span> 因为 <spanclass="math inline">\(W^TX^TY\)</span> 是一个数，因此$W<sup>TX</sup>TY=Y^TXW$ 接下来求最优 <span class="math inline">\(W 使得L\)</span> 最小</p></blockquote><p><span class="math inline">\(\hat W=\underset{W}{argmin}L(W)\)</span></p><p>令 <span class="math inline">\({\partial L(W)\over\partialW}=2X^TXW-2X^TY=0\)</span></p><blockquote><p>此处为矩阵求导，使用了基本的矩阵求导公式，其中： <spanclass="math inline">\({\partial (W^TX^TXW)\over\partialW}=X^TXW+(X^TX)^TW=2X^TXW ( X^TX 为常数)\)</span></p></blockquote><p>则$ W=(X<sup>TX)</sup>{-1}X^TY$</p><blockquote><p>视频作者说 $(X<sup>TX)</sup>{-1}X^T <spanclass="math inline">\(为伪逆，记为\)</span> A^+$ 根据线性代数来看，此处$(X<sup>TX)</sup>{-1}X^T 为 X 的左逆 X_{left}^{-1}$ 因为$X_{left}<sup>{-1}X=(X</sup>TX)<sup>{-1}(X</sup>TX)=I$</p></blockquote><h4id="最小二乘法的几何意义"><strong>2、最小二乘法的几何意义</strong></h4><h5id="从每一个数据点的误差来看"><strong>①从每一个数据点的误差来看：</strong></h5><p>每一个点对应的 <span class="math inline">\(y_i\)</span> 与其在 <spanclass="math inline">\(f(W)\)</span> 上所对应的点 <spanclass="math inline">\(W^Tx_i\)</span> 之间的差值便是误差</p><p>因此将所有点的误差求和 <spanclass="math inline">\(\displaystyle\sum^{N}_{i=1}{\VertW^Tx_i-y_i\Vert}^2\)</span> ，使得其最小，便可求得最优的回归函数</p><p><strong>②从投影角度来看：</strong></p><p><span class="math inline">\(\begin{equation}\begin{split} X_{N\timesp}W_{p \times 1}&amp;= \begin{pmatrix} x_{11}&amp;x_{12} &amp;\cdots&amp; x_{1p}\\ x_{21}&amp;x_{22}&amp;\cdots&amp;x_{2p}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\ x_{N1}&amp;x_{N2}&amp;\cdots&amp;x_{NP} \end{pmatrix} \begin{pmatrix} w_1\\w_2\\\vdots\\w_p\end{pmatrix}\\ &amp;=\begin{pmatrix}x_{11}w_1+x_{12}w_2+\cdots+x_{1p}w_p\\x_{21}w_1+x_{22}w_2+\cdots+x_{2p}w_p\\ \vdots\\x_{N1}w_1+x_{N2}w_2+\cdots+x_{Np}w_p \end{pmatrix}\\&amp;=\begin{pmatrix}w_1\begin{pmatrix}x_{11}\\x_{21}\\\vdots\\x_{N1}\end{pmatrix}+w_2\begin{pmatrix}x_{12}\\x_{22}\\\vdots\\x_{N2}\end{pmatrix} +\cdots+w_p\begin{pmatrix}x_{1p}\\x_{2p}\\\vdots\\x_{Np}\end{pmatrix}\end{pmatrix} \end{split}\end{equation}\)</span></p><p>因此可以将 <span class="math inline">\(X\)</span>中每一列看作一个向量， <span class="math inline">\(XW\)</span> 便是<span class="math inline">\(W\)</span> 对 <spanclass="math inline">\(X\)</span> 列向量的线性组合</p><blockquote><p>其实这里就是 <span class="math inline">\(X\)</span>的列空间，关于向量空间推荐观看MIT 18.06的线性代数课程，老爷子讲的非常形象！ 这里其实可以看作 <spanclass="math inline">\(X\)</span> 的所有列向量组成了一个 <spanclass="math inline">\(p\)</span> 维空间</p></blockquote><p>从二维角度来看，每一个数据点并不都在同一条直线上</p><p>引入到高维空间中，便是 <span class="math inline">\(Y\)</span> 无法由<span class="math inline">\(X\)</span> 的列向量线性表示，即 <spanclass="math inline">\(Y\)</span> 不属于 <spanclass="math inline">\(X\)</span> 的列空间，因此需要找到 <spanclass="math inline">\(Y\)</span> 在 <spanclass="math inline">\(X\)</span> 列空间上的投影（即 <spanclass="math inline">\(X\)</span> 列向量的一个线性组合）</p><blockquote><p>将 <span class="math inline">\(Y\)</span>投影在空间 <spanclass="math inline">\(F\)</span>中，便可保留 <spanclass="math inline">\(Y\)</span>在这一空间上的所有信息</p></blockquote><p>因此假设<span class="math inline">\(XW是Y在X\)</span>列空间上的投影</p><p>如上图所示，虚线部分为<spanclass="math inline">\(Y-XW\)</span>,其垂直于<spanclass="math inline">\(X\)</span>列空间（即与<spanclass="math inline">\(X\)</span>的每一个列向量都垂直）</p><p><span class="math inline">\(因此 X^T(Y-XW)=0\)</span></p><p>所以可求得 <span class="math inline">\(W=(X^TX)^{-1}X^TY\)</span></p><blockquote><p>从投影角度来看最小二乘法推荐去看MIT18.06的课程，其中专门有一节讲最小二乘法，附上视频链接如下：</p></blockquote><p><strong>总结：</strong></p><p>第一种角度是把误差分散在了每一个数据点上</p><p>第二种角度是把误差分散在了 <spanclass="math inline">\(X\)</span>的每一个列向量上， <spanclass="math inline">\(p\)</span>个维度上面</p><blockquote><p>不同的角度得到了同样的结果 横看成岭侧成峰，体现了数学的美！</p></blockquote><hr /><h3id="二线性回归2最小二乘法-概率视角-高斯噪声-mle">二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）</h3><p>最小二乘估计：</p><p><span class="math inline">\(L(W)=\displaystyle\sum^{N}_{i=1}{\VertW^Tx_i-y_i\Vert}^2\)</span></p><p><span class="math inline">\(\hat W=arg\underset{W}{min}L(W)\)</span></p><p><span class="math inline">\(\hat W=(X^TX)^{-1}X^TY\)</span></p><blockquote><p>当数据都在一条直线上时是最完美的情况，误差为0但现实中不可能出现这种情况，因为数据都带有一定的噪声</p></blockquote><p>假设噪声 <span class="math inline">\(\epsilon\simN(0,\sigma^2)\)</span></p><p><span class="math inline">\(y = f(W)+\epsilon\)</span></p><p>因为 <span class="math inline">\(f(W)=W^TX\)</span></p><p>所以 <span class="math inline">\(y=W^TX+\epsilon\)</span></p><blockquote><p>此处把 <span class="math inline">\(W^TX\)</span> 看成常数，因为当<span class="math inline">\(W\)</span> 固定后， <spanclass="math inline">\(W^TX\)</span> 是固定值</p></blockquote><p>因此 <span class="math inline">\(y|X,W\simN(W^TX,\sigma^2)\)</span></p><p><spanclass="math inline">\(p(y|X,W)={1\over\sqrt{2\pi}\sigma}\exp(-{(y-W^TX)^2\over2\sigma^2})\)</span></p><blockquote><p>接下来使用<spanclass="math inline">\(MLE\)</span>（最大似然估计）求解最优 <spanclass="math inline">\(W\)</span></p></blockquote><figure><imgsrc="C:\Users\15821\AppData\Roaming\Typora\typora-user-images\image-20230603011837692.png"alt="image-20230603011837692" /><figcaption aria-hidden="true">image-20230603011837692</figcaption></figure><figure><imgsrc="C:\Users\15821\AppData\Roaming\Typora\typora-user-images\image-20230603011920661.png"alt="image-20230603011920661" /><figcaption aria-hidden="true">image-20230603011920661</figcaption></figure><blockquote><p>此结果与上节用<span class="math inline">\(loss function求解W\)</span> 的结果一模一样 因此从概率角度用MLE求解与用最小二乘法<spanclass="math inline">\(LSE\)</span>的本质一样也因此可以得出，最小二乘估计隐含了一个噪声服从正态分布的假设</p></blockquote><p>因此 <span class="math inline">\(LSE \Leftrightarrow MLE (noise isGaussian Distribution)\)</span></p><hr /><h3 id="三线性回归3正则化-岭回归">三、线性回归3（正则化-岭回归）</h3><p><span class="math inline">\(Loss Function:L(W)=\displaystyle\sum^{N}_{i=1}{\Vert W^Tx_i-y_i\Vert}^2\)</span></p><p><span class="math inline">\(\hat W = (X^TX)^{-1}X^TY\)</span></p><blockquote><p><span class="math inline">\(其中 X_{N\times p} 为 N 个样本， p个特征， x_i \in \mathbb R^p\)</span> <span class="math inline">\(通常 N\gg p 才好\)</span> <spanclass="math inline">\(但实际问题中可能出现数据样本少，或数据的特征过多，使得N \gg p 不满足\)</span> <span class="math inline">\(此时 X^TX将不可逆，导致不能求出 \hat W 的解析解\)</span> <spanclass="math inline">\(实际上这种情况也很容易导致过拟合，因为少量样本去学习多个特征（假设1个数据点去做回归，有无数种回归方式，无论哪一种都会拟合）\)</span></p></blockquote><p><span class="math inline">\(过拟合\rightarrow \begin{cases} 1.加数据\\ 2. 降维/特征选择/特征提取(PCA)\\ 3. 正则化\end{cases}\)</span></p><p>正则化框架： <span class="math inline">\(L(W)+\lambdaP(W)\)</span></p><blockquote><p>其中L L 为Loss Function， P 为penalty（惩罚函数）</p></blockquote><p>目标： <span class="math inline">\(arg \underset{W}{min}[L(W)+\lambdaP(W)]\)</span></p><p>正则化方式：</p><p><span class="math inline">\(L1：Lasso: \ \ P(W)=\VertW\Vert\)</span></p><p><span class="math inline">\(L2：Ridge: \ \ P(W)=\Vert W\Vert^2=W^TW\)</span></p><blockquote><p>本节主要介绍L2 岭回归，也称权值衰减 下面计算添加了岭回归的LossFunction的最优 W</p></blockquote><p><span class="math inline">\(\begin{equation} \begin{split}J(W)&amp;=\displaystyle\sum^{N}_{i=1} {\Vert W^Tx_i-y_i\Vert}^2+\lambdaW^TW\\ &amp;=(W^TX^T-Y^T)(XW-Y)+\lambda W^TW\\&amp;=W^TX^TXW-Y^TXW-W^TX^TY+\lambda W^TW\\&amp;=W^TX^TXW-2W^TX^TY+\lambda W^TW\\ &amp;=W^T(X^TX+\lambdaI)W-2W^TX^TY \end{split} \end{equation}\)</span></p><blockquote><p>此推导步骤类似于第一节</p></blockquote><p>令<span class="math inline">\({\partial J(W)\over\partialW}=2(X^TX+\lambda I)W-2X^TY=0\)</span></p><p><span class="math inline">\(\hat W = (X^TX+\lambdaI)^{-1}X^TY\)</span></p><blockquote><p>其中 <span class="math inline">\(X^TX\)</span> 为半正定，当加上 <spanclass="math inline">\(\lambda I\)</span> 后必然正定，即可逆从数学角度上看，使得其可逆；从直观角度来看，抑制了过拟合的可能性</p></blockquote><hr /><h3id="四线性回归4正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-map">四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）</h3><p>本节从贝叶斯的角度来看岭回归</p><p>使用MAP（最大后验估计）计算最优参数</p><blockquote><p>此处简单介绍一下MAP是什么：MAP为贝叶斯学派常用的参数估计方法，他们认为模型参数服从某种潜在分布。其首先对参数有一个预先估计，然后根据所给数据对预估计进行不断调整，因此同一事件，先验不同则事件状态不同先验假设较为靠谱时有显著的效果，当数据较少时，先验对模型的参数有主导作用，随着数据的增加，真实数据样例将占据主导地位</p></blockquote><p>回归结果： <span class="math inline">\(f(W)=W^TX\)</span></p><p>预先所给数据： <spanclass="math inline">\(y=f(W)+\epsilon=W^TX+\epsilon\)</span></p><blockquote><p><span class="math inline">\(与第二节一样， \epsilon 为噪声(\epsilon\sim N(0,\sigma^2))\)</span> <span class="math inline">\(并且y|X;W \sim N(W^TX,\sigma^2)\)</span></p></blockquote><p>接下来使用MAP进行计算：</p><p>从MAP的角度来看，参数必然服从某个分布，故假设 <spanclass="math inline">\(W\sim N(0, \sigma^2_0)\)</span></p><p>因此： <span class="math inline">\(\hat W = arg\underset{W}{max}\ \p(W|y)\)</span></p><blockquote><p>首先根据条件概率可得 <span class="math inline">\(p(W|y)= {p(y|W)\cdotp(W)\over p(y)}\)</span> 由于已知 <spanclass="math inline">\(y|X;W\)</span> 和 <spanclass="math inline">\(W\)</span> 的分布，因此可得：</p><figure><imgsrc="C:\Users\15821\AppData\Roaming\Typora\typora-user-images\image-20230603012249079.png"alt="image-20230603012249079" /><figcaption aria-hidden="true">image-20230603012249079</figcaption></figure></blockquote><figure><imgsrc="C:\Users\15821\AppData\Roaming\Typora\typora-user-images\image-20230603012124902.png"alt="image-20230603012124902" /><figcaption aria-hidden="true">image-20230603012124902</figcaption></figure><blockquote><p>观察上式结果，其与加了Ridge正则化的Loss Function一致： <spanclass="math inline">\(J(W)=\displaystyle\sum^{N}_{i=1}{\VertW^Tx_i-y_i\Vert}^2+\lambda W^TW\)</span> <spanclass="math inline">\(其中 \lambda ={\sigma^2\over\sigma^2_0}\)</span></p></blockquote><p>根据第三节和本节内容，可以发现加入了正则项的最小二乘估计与包含服从高斯分布的噪声和先验的MAP是等价的</p><p><span class="math inline">\(regularized\ \ LSE \LeftrightarrowMAP(noise为Guassian \ Distribution;Prior为Guassian \Distribution)\)</span></p><hr /><h3 id="小结">小结</h3><p>线性回归虽然是最简单的模型，但我们通过四种不同的方法和角度得到的结果有着千丝万缕的联系。</p><p>第一节与第二节使用最小二乘法的求解结果与包含高斯噪声的MLE求解结果等价</p><p>第三节和第四节使用加了<spanclass="math inline">\(Ridge\)</span>正则项的最小二乘法求解结果与高斯先验下的MAP结果等价</p><p>因此可以大致给出他们的联系 <spanclass="math inline">\(MAP(\theta)\approxMLE(\theta)+P(\theta)\)</span></p><blockquote><p>其中MLE为概率学派常用的参数估计方法，MAP为贝叶斯学派常用的参数估计方法MLE的思想是通过数据得到参数，其完全依赖于数据，若数据过少，则很容易出现管中窥豹的情况（过拟合）MAP的思想是先给出一个预先估计（即先验证），然后根据数据进行优化，这种情况下若先验较为靠谱则效果显著若数据量大的情况下，MAP与MLE将如出一辙</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python绘图</title>
      <link href="/2023/05/25/hello-world/"/>
      <url>/2023/05/25/hello-world/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Quick Start</span><br><span class="line"></span><br><span class="line">### Create a new post</span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">$ hexo new &quot;My New Post&quot;</span><br></pre></td></tr></table></figure><p><a href="https://hexo.io/docs/one-command-deployment.html">https://hexo.io/docs/one-command-deployment.html</a>)</p>]]></content>
      
      
      <categories>
          
          <category> Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python绘图</title>
      <link href="/2023/05/25/python%E4%B8%ADmatplot/"/>
      <url>/2023/05/25/python%E4%B8%ADmatplot/</url>
      
        <content type="html"><![CDATA[<h3 id="python中matplotlib部分用法"><a href="#python中matplotlib部分用法" class="headerlink" title="python中matplotlib部分用法"></a>python中matplotlib部分用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="comment">#引入画图数据库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data for plotting</span></span><br><span class="line"></span><br><span class="line">x1=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">x2=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">x3=[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">x4=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">y1=[<span class="number">2</span>,<span class="number">5</span>,<span class="number">7</span>]</span><br><span class="line">y2=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>]</span><br><span class="line">y3=[<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]</span><br><span class="line">y4=[<span class="number">1</span>,<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line">plt.plot(x3,y3,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第一个线名字&#x27;</span>,color=<span class="string">&#x27;#F27970&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>) </span><br><span class="line"><span class="comment">#功能依次为线粗、标签(图例)、颜色、线类型、点形状</span></span><br><span class="line">plt.plot(x2,y2,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第二个线名字&#x27;</span>,color=<span class="string">&#x27;#00CC96&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>) </span><br><span class="line">plt.plot(x4,y4,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第三个线名字,color=&#x27;</span><span class="comment">#10A5EA&#x27;, linestyle=&#x27;-&#x27;,marker=&quot;,&quot;) </span></span><br><span class="line">plt.plot(x1,y1,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第四个线名字&#x27;</span>,color=<span class="string">&#x27;#8983BF&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>)  </span><br><span class="line">plt.xlabel(<span class="string">&quot;generation&quot;</span>) <span class="comment">#X轴信息</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;fitness&quot;</span>) <span class="comment">#y轴信息</span></span><br><span class="line">plt.title(<span class="string">&quot;Ant&quot;</span>) <span class="comment">#标题</span></span><br><span class="line">spines[:].set_visible(<span class="literal">False</span>) <span class="comment">#不显示边框</span></span><br><span class="line">plt.legend() <span class="comment">#标签显示（一般称为图例）</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;myplot.pdf&#x27;</span>) <span class="comment">#保存为pdf格式</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex公式格式</title>
      <link href="/2023/05/25/latex%E5%85%AC%E5%BC%8F/"/>
      <url>/2023/05/25/latex%E5%85%AC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>数学模式</p><p>在LaTeX数学模式中，公式有两种形式——行内公式和行间公式。前者公式嵌入在行内，适用于简单短小的公式；后者居中独占一行，适用于比较长或重要的公式。公式中的空格均会被忽略，可以使用命令\quad或\qquad实现<br>在行间公式中，命令\tag{n}可以进行手动编号</p><p><strong>行内公式</strong></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">$</span> f(x) = a+b <span class="built_in">$</span></span><br></pre></td></tr></table></figure><p>$ f(x) = a+b $</p><p><strong>行间公式</strong></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span> f(x) = a+b <span class="built_in">$</span><span class="built_in">$</span></span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">f(x) = a+b</script><p><strong>手动编号</strong></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\[</span>  f(x) = a - b <span class="keyword">\tag</span>&#123;1.1&#125;  <span class="keyword">\]</span></span><br></pre></td></tr></table></figure><p>[  f(x) = a - b \tag{1.1}  ]</p><h2 id="数学结构"><a href="#数学结构" class="headerlink" title="数学结构"></a>数学结构</h2><h2 id="简单运算"><a href="#简单运算" class="headerlink" title="简单运算"></a>简单运算</h2><p>拉丁字母、阿拉伯数字和 +-*/= 运算符均可以直接输入获得，命令\cdot表示乘法的圆点，命令\neq表示不等号，命令\equiv表示恒等于，命令\bmod表示取模</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ x+2-3*4/6=4/y + x\cdot y $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">x+2-3*4/6=4/y + x\cdot y</script><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ 0 \neq 1 \quad x \equiv x \quad 1 = 9 \bmod 2 $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">0 \neq 1 \quad x \equiv x \quad 1 = 9 \bmod 2</script><h2 id="上下标"><a href="#上下标" class="headerlink" title="上下标"></a>上下标</h2><p>语法_表示下标、^表示上标，但上下标内容不止一个字符时，需用大括号括起来。单引号’表示求导</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ a_&#123;ij&#125;^&#123;2&#125; + b^3_&#123;2&#125;=x^&#123;t&#125; + y&#x27; + x&#x27;&#x27;_&#123;12&#125; $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">a_{ij}^{2} + b^3_{2}=x^{t} + y' + x''_{12}</script><h2 id="根号、分式"><a href="#根号、分式" class="headerlink" title="根号、分式"></a>根号、分式</h2><p>命令：\sqrt表示平方根，\sqrt[n]表示n次方根，\frac表示分式</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\sqrt&#123;x&#125; + \sqrt&#123;x^&#123;2&#125;+\sqrt&#123;y&#125;&#125; = \sqrt[3]&#123;k_&#123;i&#125;&#125; - \frac&#123;x&#125;&#123;m&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\sqrt{x} + \sqrt{x^{2}+\sqrt{y}} = \sqrt[3]{k_{i}} - \frac{x}{m}</script><h2 id="上下标记"><a href="#上下标记" class="headerlink" title="上下标记"></a>上下标记</h2><p>命令：\overline, \underline 分别在表达式上、下方画出水平线</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\overline&#123;x+y&#125; \qquad \underline&#123;a+b&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\overline{x+y} \qquad \underline{a+b}</script><p>命令：\overbrace, \underbrace 分别在表达式上、下方给出一个水平的大括号</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\overbrace&#123;1+2+\cdots+n&#125;^&#123;n个&#125; \qquad \underbrace&#123;a+b+\cdots+z&#125;_&#123;26&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\overbrace{1+2+\cdots+n}^{n个} \qquad \underbrace{a+b+\cdots+z}_{26}</script><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><p>命令：\vec表示向量，\overrightarrow表示箭头向右的向量，\overleftarrow表示箭头向左的向量</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\vec&#123;a&#125; + \overrightarrow&#123;AB&#125; + \overleftarrow&#123;DE&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\vec{a} + \overrightarrow{AB} + \overleftarrow{DE}</script><h2 id="积分、极限、求和、乘积"><a href="#积分、极限、求和、乘积" class="headerlink" title="积分、极限、求和、乘积"></a>积分、极限、求和、乘积</h2><p>命令：\int表示积分，\lim表示极限， \sum表示求和，\prod表示乘积，^、_表示上、下限</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$  \lim_&#123;x \to \infty&#125; x^2_&#123;22&#125; - \int_&#123;1&#125;^&#123;5&#125;x\mathrm&#123;d&#125;x + \sum_&#123;n=1&#125;^&#123;20&#125; n^&#123;2&#125; = \prod_&#123;j=1&#125;^&#123;3&#125; y_&#123;j&#125;  + \lim_&#123;x \to -2&#125; \frac&#123;x-2&#125;&#123;x&#125; $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\lim_{x \to \infty} x^2_{22} - \int_{1}^{5}x\mathrm{d}x + \sum_{n=1}^{20} n^{2} = \prod_{j=1}^{3} y_{j}  + \lim_{x \to -2} \frac{x-2}{x}</script><h2 id="三圆点"><a href="#三圆点" class="headerlink" title="三圆点"></a>三圆点</h2><p>命令：\ldots点位于基线上，\cdots点设置为居中，\vdots使其垂直，\ddots对角线排列</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ x_&#123;1&#125;,x_&#123;2&#125;,\ldots,x_&#123;5&#125;  \quad x_&#123;1&#125; + x_&#123;2&#125; + \cdots + x_&#123;n&#125; $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">x_{1},x_{2},\ldots,x_{5}  \quad x_{1} + x_{2} + \cdots + x_{n}</script><h2 id="重音符号"><a href="#重音符号" class="headerlink" title="重音符号"></a>重音符号</h2><p>常用命令如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \hat&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \hat{x} $</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \bar&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \bar{x} $</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \tilde&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \tilde{x} $</p><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>其采用矩阵环境实现矩阵排列，常用的矩阵环境有matrix、bmatrix、vmatrix、pmatrix，其区别为在于外面的括号不同：</p><p><img src="https://pic1.zhimg.com/80/v2-684e48900e810dff360c23b4ffe99680_1440w.webp" alt="img"></p><p>下列代码中，&amp;用于分隔列，\用于分隔行</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;bmatrix&#125;</span><br><span class="line">1 &amp; 2 &amp; \cdots \\</span><br><span class="line">67 &amp; 95 &amp; \cdots \\</span><br><span class="line">\vdots  &amp; \vdots &amp; \ddots \\</span><br><span class="line">\end&#123;bmatrix&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{bmatrix}1 & 2 & \cdots \\67 & 95 & \cdots \\\vdots  & \vdots & \ddots \\\end{bmatrix}</script><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><p>希腊字母无法直接通过美式键盘输入获得。在LaTeX中通过反斜杠\加上其字母读音实现，将读音首字母大写即可输入其大写形式，详见下表</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \alpha^&#123;2&#125; + \beta = \Theta  $$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\alpha^{2} + \beta = \Theta</script><p><img src="https://pic1.zhimg.com/80/v2-da3e717cf670582fbfbdddee33073524_1440w.webp" alt="img"></p><h2 id="多行公式"><a href="#多行公式" class="headerlink" title="多行公式"></a>多行公式</h2><h2 id="公式组合"><a href="#公式组合" class="headerlink" title="公式组合"></a>公式组合</h2><p>通过cases环境实现公式的组合，&amp;分隔公式和条件，还可以通过\limits来让x→0位于lim的正下方而非默认在lim符号的右下方显示</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$D(x) = \begin&#123;cases&#125;</span><br><span class="line">\lim\limits_&#123;x \to 0&#125; \frac&#123;a^x&#125;&#123;b+c&#125;, &amp; x&lt;3 \\</span><br><span class="line">\pi, &amp; x=3 \\</span><br><span class="line">\int_a^&#123;3b&#125;x_&#123;ij&#125;+e^2 \mathrm&#123;d&#125;x,&amp; x&gt;3 \\</span><br><span class="line">\end&#123;cases&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">D(x) = \begin{cases}\lim\limits_{x \to 0} \frac{a^x}{b+c}, & x<3 \\\pi, & x=3 \\\int_a^{3b}x_{ij}+e^2 \mathrm{d}x,& x>3 \\\end{cases}</script><h2 id="拆分单个公式"><a href="#拆分单个公式" class="headerlink" title="拆分单个公式"></a>拆分单个公式</h2><p>通过split环境实现公式拆分</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;split&#125;</span><br><span class="line">\cos 2x &amp;= \cos^2x - \sin^2x \\</span><br><span class="line">&amp;=2\cos^2x-1</span><br><span class="line">\end&#123;split&#125;$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{split}\cos 2x &= \cos^2x - \sin^2x \\&=2\cos^2x-1\end{split}</script>]]></content>
      
      
      <categories>
          
          <category> 命令 语法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 命令 语法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java中list和map的知识点汇总</title>
      <link href="/2023/05/11/%E6%B5%8B%E8%AF%95/"/>
      <url>/2023/05/11/%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p>$\begin{equation}\begin{split} L(W)&amp;=\displaystyle\sum^{N}_{i=1}(W^Tx_i-y_i)^2\ &amp;= \begin{pmatrix} W^Tx_1-y_1 &amp; W^Tx_2-y_2&amp;\cdots&amp;W^Tx_N-y_N \end{pmatrix} \begin{pmatrix} (W^Tx_1-y_1)^T\(W^Tx_2-y_2)^T\\vdots\(W^Tx_N-y_N)^T \end{pmatrix}\ &amp;=[W^T\begin{pmatrix} x_1&amp;x_2&amp;\cdots&amp;x_N \end{pmatrix} -\begin{pmatrix} y_1&amp;y_2&amp;\cdots&amp;y_N \end{pmatrix}] \begin{pmatrix} x_1^TW-y_1^T\x_2^TW-y_2^T\\vdots\x_N^TW-y_N^T \end{pmatrix}\ &amp;=(W^TX^T - Y^T)(XW-Y)\ &amp;=W^TX^TXW-W^TX^TY-Y^TXW+Y^TY\ &amp;=W^TX^TXW-2W^TX^TY+Y^TY \end{split}\end{equation}$</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> testTag </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
