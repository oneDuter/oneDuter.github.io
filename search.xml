<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>线性回归</title>
      <link href="/2023/05/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
      <url>/2023/05/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h2 id="本章内容："><a href="#本章内容：" class="headerlink" title="本章内容："></a>本章内容：</h2><p><a href="#%E4%B8%80%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921%EF%BC%88%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%8F%8A%E5%85%B6%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%EF%BC%89"><strong>1、最小二乘法（矩阵表达与几何意义）</strong></a></p><p><a href="#%E4%BA%8C%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%922%EF%BC%88%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-%E6%A6%82%E7%8E%87%E8%A7%86%E8%A7%92-%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0-MLE%EF%BC%89"><strong>2、概率角度：最小二乘法 \Leftrightarrow noise为Gaussian 的 MLE（最大似然估计）</strong></a></p><p><a href="#%E4%B8%89%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%923%EF%BC%88%E6%AD%A3%E5%88%99%E5%8C%96-%E5%B2%AD%E5%9B%9E%E5%BD%92%EF%BC%89"><strong>3、正则化 \begin{cases} L1 \rightarrow Lasso\ L2 \rightarrow Ridge(岭回归)\ \end{cases}</strong></a></p><p><strong><a href="#%E5%9B%9B%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%924%EF%BC%88%E6%AD%A3%E5%88%99%E5%8C%96-%E5%B2%AD%E5%9B%9E%E5%BD%92-%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%92%E5%BA%A6-%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0%E9%AB%98%E6%96%AF%E5%85%88%E9%AA%8C-MAP%EF%BC%89">4、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）</a></strong></p><p><strong><a href="#%E5%B0%8F%E7%BB%93">5、小结</a></strong></p><p><strong>符号说明：</strong></p><p>$D&#x3D;{ (x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)} $(数据集)</p><p>$x_i\in \mathbb R^p y_i \in \mathbb R i&#x3D;1,2,\cdots ,N$</p>$X=\begin{pmatrix} x_1&x_2& \cdots& x_N \end{pmatrix}^T= \begin{pmatrix} x_1^T\\x_2^T\\\vdots\\x_N^T \end{pmatrix}= \begin{pmatrix} x_{11}&x_{12} & \cdots& x_{1p}\\ x_{21}&x_{22}&\cdots&x_{2p}\\ \vdots&\vdots&\ddots&\vdots\\ x_{N1}&x_{N2}&\cdots &x_{NP} \end{pmatrix}_{N\times P}$$Y=\begin{pmatrix} y_1\\y_2\\\vdots\\y_N \end{pmatrix}_{N\times 1}$<h3 id="一、线性回归1（最小二乘法及其几何意义）"><a href="#一、线性回归1（最小二乘法及其几何意义）" class="headerlink" title="一、线性回归1（最小二乘法及其几何意义）"></a>一、线性回归1（最小二乘法及其几何意义）</h3><h4 id="1、矩阵表达下的最小二乘法"><a href="#1、矩阵表达下的最小二乘法" class="headerlink" title="1、矩阵表达下的最小二乘法"></a><strong>1、矩阵表达下的最小二乘法</strong></h4><p>$<strong>Loss Function:</strong>$</p><p>$L(W)&#x3D;\displaystyle\sum^{N}_{i&#x3D;1}{\Vert W^Tx_i-y_i\Vert}^2$</p><blockquote><p>此式为均方差，若 $L$ 越小，则回归结果与真实结果越接近<br>此处 $W$ 是一个 $p\times 1$ 的向量，表示 $x_i$ 的系数<br>一般情况应该是 $W^Tx_i+b$ 此处在 $x_i$ 中增加一个 $x_{i0}&#x3D;1$ ，在 $W$ 中增加一个 $w_0&#x3D;b$ ，即可用 $W^Tx_i$ 表示</p></blockquote>$\begin{equation}\begin{split} L(W)&=\displaystyle\sum^{N}_{i=1}(W^Tx_i-y_i)^2\\ &= \begin{pmatrix} W^Tx_1-y_1 & W^Tx_2-y_2&\cdots&W^Tx_N-y_N \end{pmatrix} \begin{pmatrix} (W^Tx_1-y_1)^T\\(W^Tx_2-y_2)^T\\\vdots\\(W^Tx_N-y_N)^T \end{pmatrix}\\ &=[W^T\begin{pmatrix} x_1&x_2&\cdots&x_N \end{pmatrix} -\begin{pmatrix} y_1&y_2&\cdots&y_N \end{pmatrix}] \begin{pmatrix} x_1^TW-y_1^T\\x_2^TW-y_2^T\\\vdots\\x_N^TW-y_N^T \end{pmatrix}\\ &=(W^TX^T - Y^T)(XW-Y)\\ &=W^TX^TXW-W^TX^TY-Y^TXW+Y^TY\\ &=W^TX^TXW-2W^TX^TY+Y^TY \end{split}\end{equation}$<blockquote><p>$W^TX^TY&#x3D;(Y^TXW)^T$<br>因为 $W^TX^TY$ 是一个数，因此$ W^TX^TY&#x3D;Y^TXW$<br>接下来求最优 $W 使得 L$ 最小</p></blockquote><p>$\hat W&#x3D;\underset {W}{argmin}L(W)$</p><p>令 ${\partial L(W)\over\partial W}&#x3D;2X^TXW-2X^TY&#x3D;0$</p><blockquote><p>此处为矩阵求导，使用了基本的矩阵求导公式，其中：<br>${\partial (W^TX^TXW)\over\partial W}&#x3D;X^TXW+(X^TX)^TW&#x3D;2X^TXW ( X^TX 为常数)$</p></blockquote><p>则$ W&#x3D;(X^TX)^{-1}X^TY$</p><blockquote><p>视频作者说 $(X^TX)^{-1}X^T $为伪逆，记为$ A^+$<br>根据线性代数来看，此处$ (X^TX)^{-1}X^T 为 X 的左逆 X_{left}^{-1}$<br>因为$ X_{left}^{-1}\cdot X&#x3D;(X^TX)^{-1}(X^TX)&#x3D;I$</p></blockquote><h4 id="2、最小二乘法的几何意义"><a href="#2、最小二乘法的几何意义" class="headerlink" title="2、最小二乘法的几何意义"></a><strong>2、最小二乘法的几何意义</strong></h4><h5 id="①从每一个数据点的误差来看："><a href="#①从每一个数据点的误差来看：" class="headerlink" title="①从每一个数据点的误差来看："></a><strong>①从每一个数据点的误差来看：</strong></h5><p>每一个点对应的 $y_i$ 与其在 $f(W)$ 上所对应的点 $W^Tx_i$ 之间的差值便是误差</p><p>因此将所有点的误差求和 $\displaystyle\sum^{N}_{i&#x3D;1}{\Vert W^Tx_i-y_i\Vert}^2$ ，使得其最小，便可求得最优的回归函数</p><p><strong>②从投影角度来看：</strong></p>$\begin{equation}\begin{split} X_{N\times p}W_{p \times 1}&= \begin{pmatrix} x_{11}&x_{12} & \cdots& x_{1p}\\ x_{21}&x_{22}&\cdots&x_{2p}\\ \vdots&\vdots&\ddots&\vdots\\ x_{N1}&x_{N2}&\cdots &x_{NP} \end{pmatrix} \begin{pmatrix} w_1\\w_2\\\vdots\\w_p \end{pmatrix}\\ &=\begin{pmatrix} x_{11}w_1+x_{12}w_2+\cdots+x_{1p}w_p\\ x_{21}w_1+x_{22}w_2+\cdots+x_{2p}w_p\\ \vdots\\ x_{N1}w_1+x_{N2}w_2+\cdots+x_{Np}w_p \end{pmatrix}\\ &=\begin{pmatrix} w_1\begin{pmatrix}x_{11}\\x_{21}\\\vdots\\x_{N1}\end{pmatrix} +w_2\begin{pmatrix}x_{12}\\x_{22}\\\vdots\\x_{N2}\end{pmatrix} +\cdots+ w_p\begin{pmatrix}x_{1p}\\x_{2p}\\\vdots\\x_{Np}\end{pmatrix} \end{pmatrix} \end{split}\end{equation}$<p>因此可以将 $X$ 中每一列看作一个向量， $XW$ 便是 $W$ 对 $X$ 列向量的线性组合</p><blockquote><p>其实这里就是 $X$ 的列空间，关于向量空间推荐观看MIT 18.06 的线性代数课程，老爷子讲的非常形象！<br>这里其实可以看作 $X$ 的所有列向量组成了一个 $p$ 维空间</p></blockquote><p>从二维角度来看，每一个数据点并不都在同一条直线上</p><p>引入到高维空间中，便是 $Y$ 无法由 $X$ 的列向量线性表示，即 $Y$ 不属于 $X$ 的列空间，因此需要找到 $Y$ 在 $X$ 列空间上的投影（即 $X$ 列向量的一个线性组合）</p><blockquote><p>将 $Y$投影在空间 $F$中，便可保留 $Y$在这一空间上的所有信息</p></blockquote><p>因此假设$XW是Y在 X$列空间上的投影</p><p>如上图所示，虚线部分为$Y-XW$,其垂直于$X$列空间（即与$X$的每一个列向量都垂直）</p><p>$因此 X^T(Y-XW)&#x3D;0$</p><p>所以可求得 $W&#x3D;(X^TX)^{-1}X^TY$</p><blockquote><p>从投影角度来看最小二乘法推荐去看MIT 18.06的课程，其中专门有一节讲最小二乘法，附上视频链接如下：</p></blockquote><p><strong>总结：</strong></p><p>第一种角度是把误差分散在了每一个数据点上</p><p>第二种角度是把误差分散在了 $X$的每一个列向量上， $p$个维度上面</p><blockquote><p>不同的角度得到了同样的结果<br>横看成岭侧成峰，体现了数学的美！</p></blockquote><hr><h3 id="二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）"><a href="#二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）" class="headerlink" title="二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）"></a>二、线性回归2（最小二乘法-概率视角-高斯噪声-MLE）</h3><p>最小二乘估计：</p><p>$L(W)&#x3D;\displaystyle\sum^{N}_{i&#x3D;1}{\Vert W^Tx_i-y_i\Vert}^2$</p><p>$\hat W&#x3D;arg\underset {W}{min}L(W)$</p><p>$\hat W&#x3D;(X^TX)^{-1}X^TY$</p><blockquote><p>当数据都在一条直线上时是最完美的情况，误差为0<br>但现实中不可能出现这种情况，因为数据都带有一定的噪声</p></blockquote><p>假设噪声 $\epsilon\sim N(0,\sigma^2)$</p><p>$y &#x3D; f(W)+\epsilon$</p><p>因为 $f(W)&#x3D;W^TX$</p><p>所以 $y&#x3D;W^TX+\epsilon$</p><blockquote><p>此处把 $W^TX$ 看成常数，因为当 $W$ 固定后， $W^TX$ 是固定值</p></blockquote><p>因此 $y|X,W\sim N(W^TX,\sigma^2)$</p><p>$p(y|X,W)&#x3D;{1\over \sqrt{2\pi}\sigma}\exp(-{(y-W^TX)^2\over 2\sigma^2})$</p><blockquote><p>接下来使用$MLE$（最大似然估计）求解最优 $W$</p></blockquote>$\begin{equation}\begin{split} L(W)&=\log{p(y|X,W)}\\ &=\log\displaystyle\prod^N_{i=1}{p(y_i|x_i,W)}\\ &=\displaystyle\sum^N_{i=1}{\log p(y_i|x_i,W)}\\ &=\displaystyle\sum^N_{i=1}{\log ({1\over \sqrt{2\pi}\sigma}\exp(-{(y_i-W^Tx_i)^2\over 2\sigma^2})})\\ &=\displaystyle\sum^N_{i=1}\log{{1\over \sqrt{2\pi}\sigma}-{(y_i-W^Tx_i)^2\over 2\sigma^2}} \end{split}\end{equation}$$\begin{equation}\begin{split} \hat W&=arg\underset {W}{max}\ L(W)\\ &=arg\underset {W}{max}\ \displaystyle\sum^N_{i=1}{\log{{1\over \sqrt{2\pi}\sigma}-{(y_i-W^Tx_i)^2\over 2\sigma^2}}}\\ &=arg\underset {W}{max}\ \displaystyle\sum^N_{i=1}{-{(y_i-W^Tx_i)^2\over 2\sigma^2}}\\ &=arg\underset {W}{min}\ \displaystyle\sum^N_{i=1}{{(y_i-W^Tx_i)^2\over 2\sigma^2}}\\ &=arg\underset {W}{min}\ \displaystyle\sum^N_{i=1}{(y_i-W^Tx_i)^2} \end{split}\end{equation}$<blockquote><p>此结果与上节用$loss function求解 W$ 的结果一模一样<br>因此从概率角度用MLE求解与用最小二乘法$LSE$的本质一样<br>也因此可以得出，最小二乘估计隐含了一个噪声服从正态分布的假设</p></blockquote><p>因此 $LSE \Leftrightarrow MLE (noise is Gaussian Distribution)$</p><hr><h3 id="三、线性回归3（正则化-岭回归）"><a href="#三、线性回归3（正则化-岭回归）" class="headerlink" title="三、线性回归3（正则化-岭回归）"></a>三、线性回归3（正则化-岭回归）</h3><p>$Loss Function: L(W)&#x3D;\displaystyle\sum^{N}_{i&#x3D;1}{\Vert W^Tx_i-y_i\Vert}^2$</p><p>$\hat W &#x3D; (X^TX)^{-1}X^TY$</p><blockquote><p>$其中 X_{N\times p} 为 N 个样本， p 个特征， x_i \in \mathbb R^p$<br>$通常 N \gg p 才好$<br>$但实际问题中可能出现数据样本少，或数据的特征过多，使得 N \gg p 不满足$<br>$此时 X^TX 将不可逆，导致不能求出 \hat W 的解析解$<br>$实际上这种情况也很容易导致过拟合，因为少量样本去学习多个特征（假设1个数据点去做回归，有无数种回归方式，无论哪一种都会拟合）$</p></blockquote><p>$过拟合\rightarrow \begin{cases} 1. 加数据\ 2. 降维&#x2F;特征选择&#x2F;特征提取(PCA)\ 3. 正则化 \end{cases}$</p><p>正则化框架： $L(W)+\lambda P(W)$</p><blockquote><p>其中L L 为Loss Function， P 为penalty（惩罚函数）</p></blockquote><p>目标： $arg \underset{W}{min}[L(W)+\lambda P(W)]$</p><p>正则化方式：</p><p>$L1：Lasso: \ \ P(W)&#x3D;\Vert W\Vert$</p><p>$L2：Ridge: \ \ P(W)&#x3D;\Vert W\Vert ^2&#x3D;W^TW$</p><blockquote><p>本节主要介绍L2 岭回归，也称权值衰减<br>下面计算添加了岭回归的Loss Function的最优 W</p></blockquote>$\begin{equation} \begin{split} J(W)&=\displaystyle\sum^{N}_{i=1} {\Vert W^Tx_i-y_i\Vert}^2+\lambda W^TW\\ &=(W^TX^T-Y^T)(XW-Y)+\lambda W^TW\\ &=W^TX^TXW-Y^TXW-W^TX^TY+\lambda W^TW\\ &=W^TX^TXW-2W^TX^TY+\lambda W^TW\\ &=W^T(X^TX+\lambda I)W-2W^TX^TY \end{split} \end{equation}$ <blockquote><p>此推导步骤类似于第一节</p></blockquote><p>令${\partial J(W)\over \partial W}&#x3D;2(X^TX+\lambda I)W-2X^TY&#x3D;0$</p><p>$\hat W &#x3D; (X^TX+\lambda I)^{-1}X^TY$</p><blockquote><p>其中 X^TX 为半正定，当加上 $\lambda I$ 后必然正定，即可逆<br>从数学角度上看，使得其可逆；从直观角度来看，抑制了过拟合的可能性</p></blockquote><hr><h3 id="四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）"><a href="#四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）" class="headerlink" title="四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）"></a>四、线性回归4（正则化-岭回归-贝叶斯角度-高斯噪声高斯先验-MAP）</h3><p>本节从贝叶斯的角度来看岭回归</p><p>使用MAP（最大后验估计）计算最优参数</p><blockquote><p>此处简单介绍一下MAP是什么：<br>MAP为贝叶斯学派常用的参数估计方法，他们认为模型参数服从某种潜在分布。<br>其首先对参数有一个预先估计，然后根据所给数据对预估计进行不断调整，因此同一事件，先验不同则事件状态不同<br>先验假设较为靠谱时有显著的效果，当数据较少时，先验对模型的参数有主导作用，随着数据的增加，真实数据样例将占据主导地位</p></blockquote><p>回归结果： $f(W)&#x3D;W^TX$</p><p>预先所给数据： $y&#x3D;f(W)+\epsilon&#x3D;W^TX+\epsilon$</p><blockquote><p>$与第二节一样， \epsilon 为噪声 (\epsilon\sim N(0,\sigma^2))$<br>$并且 y|X;W \sim N(W^TX,\sigma^2)$</p></blockquote><p>接下来使用MAP进行计算：</p><p>从MAP的角度来看，参数必然服从某个分布，故假设 $W\sim N(0, \sigma^2_0)$</p><p>因此： $\hat W &#x3D; arg\underset{W}{max}\ \ p(W|y)$</p><blockquote><p>首先根据条件概率可得 $p(W|y)&#x3D; {p(y|W)\cdot p(W)\over p(y)}$<br>由于已知 $y|X;W$ 和 $W$ 的分布，因此可得：</p>>> $p(y|W)={1\over\sqrt{2\pi}\sigma}\exp{\{-{(y-W^TX)^2\over2\sigma^2}\}}$>> >> $p(W)={1\over\sqrt{2\pi}\sigma_0}\exp{\{-{\Vert W\Vert^2\over2\sigma_0^2}\}}$>> </blockquote>$\begin{equation}\begin{split} \hat W &= arg\underset{W}{max}\ \ {p(y|W)p(W)\over p(y)}\\ &=arg\underset{W}{max}\ \ p(y|W)p(W)\\ &=arg\underset{W}{max}\ \ \log{\{p(y|W)p(W) \}}\\ &=arg\underset{W}{max}\ \ \log{\{{1\over\sqrt{2\pi}\sigma}\exp{\{-{(y-W^TX)^2\over2\sigma^2}\}}{1\over\sqrt{2\pi}\sigma_0}\exp{\{-{\Vert W\Vert^2\over2\sigma_0^2}\}}\}}\\ &=arg\underset{W}{max}\ \ \log{({1\over\sqrt{2\pi}\sigma}{1\over\sqrt{2\pi}\sigma_0})}-{(y-W^TX)^2\over2\sigma^2}-{\Vert W\Vert^2\over2\sigma_0^2}\\ &=arg\underset{W}{max}\ \ -{(y-W^TX)^2\over2\sigma^2}-{\Vert W\Vert^2\over2\sigma_0^2}\\ &=arg\underset{W}{min}\ \ {(y-W^TX)^2\over2\sigma^2}+{\Vert W\Vert^2\over2\sigma_0^2}\\ &=arg\underset{W}{min}\ \ (y-W^TX)^2+{\sigma^2\over \sigma^2_0}\Vert W \Vert ^2\\ &=arg\underset{W}{min}\ \ \sum^N_{i=1}(y_i-W^Tx_i)^2+{\sigma^2\over \sigma^2_0}\Vert W \Vert ^2\\ \end{split}\end{equation}$ <blockquote><p>观察上式结果，其与加了Ridge正则化的Loss Function一致：<br>$J(W)&#x3D;\displaystyle\sum^{N}_{i&#x3D;1}{\Vert W^Tx_i-y_i\Vert}^2+\lambda W^TW$<br>$其中 \lambda &#x3D; {\sigma^2\over \sigma^2_0}$</p></blockquote><p>根据第三节和本节内容，可以发现加入了正则项的最小二乘估计与包含服从高斯分布的噪声和先验的MAP是等价的</p><p>$regularized\ \ LSE \Leftrightarrow MAP(noise为Guassian \ Distribution;Prior为Guassian \ Distribution)$</p><hr><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>线性回归虽然是最简单的模型，但我们通过四种不同的方法和角度得到的结果有着千丝万缕的联系。</p><p>第一节与第二节使用最小二乘法的求解结果与包含高斯噪声的MLE求解结果等价</p><p>第三节和第四节使用加了$Ridge$正则项的最小二乘法求解结果与高斯先验下的MAP结果等价</p><p>因此可以大致给出他们的联系 $MAP(\theta)\approx MLE(\theta)+P(\theta)$</p><blockquote><p>其中MLE为概率学派常用的参数估计方法，MAP为贝叶斯学派常用的参数估计方法<br>MLE的思想是通过数据得到参数，其完全依赖于数据，若数据过少，则很容易出现管中窥豹的情况（过拟合）<br>MAP的思想是先给出一个预先估计（即先验证），然后根据数据进行优化，这种情况下若先验较为靠谱则效果显著<br>若数据量大的情况下，MAP与MLE将如出一辙</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python绘图</title>
      <link href="/2023/05/25/python%E4%B8%ADmatplot/"/>
      <url>/2023/05/25/python%E4%B8%ADmatplot/</url>
      
        <content type="html"><![CDATA[<h3 id="python中matplotlib部分用法"><a href="#python中matplotlib部分用法" class="headerlink" title="python中matplotlib部分用法"></a>python中matplotlib部分用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="comment">#引入画图数据库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data for plotting</span></span><br><span class="line"></span><br><span class="line">x1=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">x2=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">x3=[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">x4=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">y1=[<span class="number">2</span>,<span class="number">5</span>,<span class="number">7</span>]</span><br><span class="line">y2=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>]</span><br><span class="line">y3=[<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]</span><br><span class="line">y4=[<span class="number">1</span>,<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line">plt.plot(x3,y3,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第一个线名字&#x27;</span>,color=<span class="string">&#x27;#F27970&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>) </span><br><span class="line"><span class="comment">#功能依次为线粗、标签(图例)、颜色、线类型、点形状</span></span><br><span class="line">plt.plot(x2,y2,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第二个线名字&#x27;</span>,color=<span class="string">&#x27;#00CC96&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>) </span><br><span class="line">plt.plot(x4,y4,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第三个线名字,color=&#x27;</span><span class="comment">#10A5EA&#x27;, linestyle=&#x27;-&#x27;,marker=&quot;,&quot;) </span></span><br><span class="line">plt.plot(x1,y1,linewidth =<span class="number">3.0</span>, label = <span class="string">&#x27;第四个线名字&#x27;</span>,color=<span class="string">&#x27;#8983BF&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>,marker=<span class="string">&quot;,&quot;</span>)  </span><br><span class="line">plt.xlabel(<span class="string">&quot;generation&quot;</span>) <span class="comment">#X轴信息</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;fitness&quot;</span>) <span class="comment">#y轴信息</span></span><br><span class="line">plt.title(<span class="string">&quot;Ant&quot;</span>) <span class="comment">#标题</span></span><br><span class="line">spines[:].set_visible(<span class="literal">False</span>) <span class="comment">#不显示边框</span></span><br><span class="line">plt.legend() <span class="comment">#标签显示（一般称为图例）</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;myplot.pdf&#x27;</span>) <span class="comment">#保存为pdf格式</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python绘图</title>
      <link href="/2023/05/25/hello-world/"/>
      <url>/2023/05/25/hello-world/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Quick Start</span><br><span class="line"></span><br><span class="line">### Create a new post</span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">$ hexo new &quot;My New Post&quot;</span><br></pre></td></tr></table></figure><p><a href="https://hexo.io/docs/one-command-deployment.html">https://hexo.io/docs/one-command-deployment.html</a>)</p>]]></content>
      
      
      <categories>
          
          <category> Algorithms </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex公式格式</title>
      <link href="/2023/05/25/latex%E5%85%AC%E5%BC%8F/"/>
      <url>/2023/05/25/latex%E5%85%AC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>数学模式</p><p>在LaTeX数学模式中，公式有两种形式——行内公式和行间公式。前者公式嵌入在行内，适用于简单短小的公式；后者居中独占一行，适用于比较长或重要的公式。公式中的空格均会被忽略，可以使用命令\quad或\qquad实现<br>在行间公式中，命令\tag{n}可以进行手动编号</p><p><strong>行内公式</strong></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">$</span> f(x) = a+b <span class="built_in">$</span></span><br></pre></td></tr></table></figure><p>$ f(x) &#x3D; a+b $</p><p><strong>行间公式</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ f(x) = a+b $$</span><br></pre></td></tr></table></figure><p>$$ f(x) &#x3D; a+b $$</p><p><strong>手动编号</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\[  f(x) = a - b \tag&#123;1.1&#125;  \]</span><br></pre></td></tr></table></figure><p>[  f(x) &#x3D; a - b \tag{1.1}  ]</p><h2 id="数学结构"><a href="#数学结构" class="headerlink" title="数学结构"></a>数学结构</h2><h2 id="简单运算"><a href="#简单运算" class="headerlink" title="简单运算"></a>简单运算</h2><p>拉丁字母、阿拉伯数字和 +-*&#x2F;&#x3D; 运算符均可以直接输入获得，命令\cdot表示乘法的圆点，命令\neq表示不等号，命令\equiv表示恒等于，命令\bmod表示取模</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ x+2-3*4/6=4/y + x\cdot y $$</span><br></pre></td></tr></table></figure><p>$$ x+2-3*4&#x2F;6&#x3D;4&#x2F;y + x\cdot y $$</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ 0 \neq 1 \quad x \equiv x \quad 1 = 9 \bmod 2 $$</span><br></pre></td></tr></table></figure><p>$$ 0 \neq 1 \quad x \equiv x \quad 1 &#x3D; 9 \bmod 2 $$</p><h2 id="上下标"><a href="#上下标" class="headerlink" title="上下标"></a>上下标</h2><p>语法_表示下标、^表示上标，但上下标内容不止一个字符时，需用大括号括起来。单引号’表示求导</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ a_&#123;ij&#125;^&#123;2&#125; + b^3_&#123;2&#125;=x^&#123;t&#125; + y&#x27; + x&#x27;&#x27;_&#123;12&#125; $$</span><br></pre></td></tr></table></figure><p>$$ a_{ij}^{2} + b^3_{2}&#x3D;x^{t} + y’ + x’’_{12} $$</p><h2 id="根号、分式"><a href="#根号、分式" class="headerlink" title="根号、分式"></a>根号、分式</h2><p>命令：\sqrt表示平方根，\sqrt[n]表示n次方根，\frac表示分式</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\sqrt&#123;x&#125; + \sqrt&#123;x^&#123;2&#125;+\sqrt&#123;y&#125;&#125; = \sqrt[3]&#123;k_&#123;i&#125;&#125; - \frac&#123;x&#125;&#123;m&#125;$$</span><br></pre></td></tr></table></figure><p>$$\sqrt{x} + \sqrt{x^{2}+\sqrt{y}} &#x3D; \sqrt[3]{k_{i}} - \frac{x}{m}$$</p><h2 id="上下标记"><a href="#上下标记" class="headerlink" title="上下标记"></a>上下标记</h2><p>命令：\overline, \underline 分别在表达式上、下方画出水平线</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\overline&#123;x+y&#125; \qquad \underline&#123;a+b&#125;$$</span><br></pre></td></tr></table></figure><p>$$\overline{x+y} \qquad \underline{a+b}$$</p><p>命令：\overbrace, \underbrace 分别在表达式上、下方给出一个水平的大括号</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\overbrace&#123;1+2+\cdots+n&#125;^&#123;n个&#125; \qquad \underbrace&#123;a+b+\cdots+z&#125;_&#123;26&#125;$$</span><br></pre></td></tr></table></figure><p>$$\overbrace{1+2+\cdots+n}^{n个} \qquad \underbrace{a+b+\cdots+z}_{26}$$</p><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><p>命令：\vec表示向量，\overrightarrow表示箭头向右的向量，\overleftarrow表示箭头向左的向量</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$\vec&#123;a&#125; + \overrightarrow&#123;AB&#125; + \overleftarrow&#123;DE&#125;$$</span><br></pre></td></tr></table></figure><p>$$\vec{a} + \overrightarrow{AB} + \overleftarrow{DE}$$</p><h2 id="积分、极限、求和、乘积"><a href="#积分、极限、求和、乘积" class="headerlink" title="积分、极限、求和、乘积"></a>积分、极限、求和、乘积</h2><p>命令：\int表示积分，\lim表示极限， \sum表示求和，\prod表示乘积，^、_表示上、下限</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$  \lim_&#123;x \to \infty&#125; x^2_&#123;22&#125; - \int_&#123;1&#125;^&#123;5&#125;x\mathrm&#123;d&#125;x + \sum_&#123;n=1&#125;^&#123;20&#125; n^&#123;2&#125; = \prod_&#123;j=1&#125;^&#123;3&#125; y_&#123;j&#125;  + \lim_&#123;x \to -2&#125; \frac&#123;x-2&#125;&#123;x&#125; $$</span><br></pre></td></tr></table></figure><p>$$  \lim_{x \to \infty} x^2_{22} - \int_{1}^{5}x\mathrm{d}x + \sum_{n&#x3D;1}^{20} n^{2} &#x3D; \prod_{j&#x3D;1}^{3} y_{j}  + \lim_{x \to -2} \frac{x-2}{x} $$</p><h2 id="三圆点"><a href="#三圆点" class="headerlink" title="三圆点"></a>三圆点</h2><p>命令：\ldots点位于基线上，\cdots点设置为居中，\vdots使其垂直，\ddots对角线排列</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ x_&#123;1&#125;,x_&#123;2&#125;,\ldots,x_&#123;5&#125;  \quad x_&#123;1&#125; + x_&#123;2&#125; + \cdots + x_&#123;n&#125; $$</span><br></pre></td></tr></table></figure><p>$$ x_{1},x_{2},\ldots,x_{5}  \quad x_{1} + x_{2} + \cdots + x_{n} $$</p><h2 id="重音符号"><a href="#重音符号" class="headerlink" title="重音符号"></a>重音符号</h2><p>常用命令如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \hat&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \hat{x} $</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \bar&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \bar{x} $</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ \tilde&#123;x&#125; $</span><br></pre></td></tr></table></figure><p>$ \tilde{x} $</p><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>其采用矩阵环境实现矩阵排列，常用的矩阵环境有matrix、bmatrix、vmatrix、pmatrix，其区别为在于外面的括号不同：</p><p><img src="https://pic1.zhimg.com/80/v2-684e48900e810dff360c23b4ffe99680_1440w.webp" alt="img"></p><p>下列代码中，&amp;用于分隔列，\用于分隔行</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;bmatrix&#125;</span><br><span class="line">1 &amp; 2 &amp; \cdots \\</span><br><span class="line">67 &amp; 95 &amp; \cdots \\</span><br><span class="line">\vdots  &amp; \vdots &amp; \ddots \\</span><br><span class="line">\end&#123;bmatrix&#125;$$</span><br></pre></td></tr></table></figure><p>$$\begin{bmatrix}<br>1 &amp; 2 &amp; \cdots \<br>67 &amp; 95 &amp; \cdots \<br>\vdots  &amp; \vdots &amp; \ddots \<br>\end{bmatrix}$$</p><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><p>希腊字母无法直接通过美式键盘输入获得。在LaTeX中通过反斜杠\加上其字母读音实现，将读音首字母大写即可输入其大写形式，详见下表</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \alpha^&#123;2&#125; + \beta = \Theta  $$</span><br></pre></td></tr></table></figure><p>$$ \alpha^{2} + \beta &#x3D; \Theta  $$</p><p><img src="https://pic1.zhimg.com/80/v2-da3e717cf670582fbfbdddee33073524_1440w.webp" alt="img"></p><h2 id="多行公式"><a href="#多行公式" class="headerlink" title="多行公式"></a>多行公式</h2><h2 id="公式组合"><a href="#公式组合" class="headerlink" title="公式组合"></a>公式组合</h2><p>通过cases环境实现公式的组合，&amp;分隔公式和条件，还可以通过\limits来让x→0位于lim的正下方而非默认在lim符号的右下方显示</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$D(x) = \begin&#123;cases&#125;</span><br><span class="line">\lim\limits_&#123;x \to 0&#125; \frac&#123;a^x&#125;&#123;b+c&#125;, &amp; x&lt;3 \\</span><br><span class="line">\pi, &amp; x=3 \\</span><br><span class="line">\int_a^&#123;3b&#125;x_&#123;ij&#125;+e^2 \mathrm&#123;d&#125;x,&amp; x&gt;3 \\</span><br><span class="line">\end&#123;cases&#125;$$</span><br></pre></td></tr></table></figure><p>$$D(x) &#x3D; \begin{cases}<br>\lim\limits_{x \to 0} \frac{a^x}{b+c}, &amp; x&lt;3 \<br>\pi, &amp; x&#x3D;3 \<br>\int_a^{3b}x_{ij}+e^2 \mathrm{d}x,&amp; x&gt;3 \<br>\end{cases}$$</p><h2 id="拆分单个公式"><a href="#拆分单个公式" class="headerlink" title="拆分单个公式"></a>拆分单个公式</h2><p>通过split环境实现公式拆分</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;split&#125;</span><br><span class="line">\cos 2x &amp;= \cos^2x - \sin^2x \\</span><br><span class="line">&amp;=2\cos^2x-1</span><br><span class="line">\end&#123;split&#125;$$</span><br></pre></td></tr></table></figure><p>$$\begin{split}<br>\cos 2x &amp;&#x3D; \cos^2x - \sin^2x \<br>&amp;&#x3D;2\cos^2x-1<br>\end{split}$$</p>]]></content>
      
      
      <categories>
          
          <category> 命令 语法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 命令 语法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java中list和map的知识点汇总</title>
      <link href="/2023/05/11/%E6%B5%8B%E8%AF%95/"/>
      <url>/2023/05/11/%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> testTag </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
